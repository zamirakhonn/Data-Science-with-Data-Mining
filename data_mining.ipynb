{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c746f900-710b-40f5-950b-34f33ea0c3ea",
   "metadata": {},
   "source": [
    "# Data Science with Data Mining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102ec31-5e1e-482b-ae9e-5e2c6df21855",
   "metadata": {},
   "source": [
    "##### Data mining is the process of finding useful patterns and information in large amounts of data. It's like looking for hidden treasures in a big pile of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e5bf1-ac10-4eaa-abd5-80d1fdf9df8b",
   "metadata": {},
   "source": [
    "#### Python tools for libraries for Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff1c8881-2c12-44d5-9c13-f6c8f7210af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0] [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Pandas is a powerful and widely used Python library for data manipulation and analysis.\n",
    "# Scikit-learn is a popular Python library for machine learning.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100)  # Create the RandomForestClassifier\n",
    "model.fit(X_train, y_train)  # Train the model\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\",y_test, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806dc0bc-e673-4be0-92f8-b6cb4c4078a6",
   "metadata": {},
   "source": [
    "## Calculate metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cad02e9-e2a0-4aa7-96d6-c5f7d55c36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6995635-c333-4aef-be9e-7206abae1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyCaret - is an open source machine learning library that simplifies the process of building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbde4d1-bea3-478a-b667-d55fe2faa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import pycaret\n",
    "\n",
    "# Load the dataset (e.g., Iris dataset)\n",
    "data = get_data('iris')\n",
    "\n",
    "# Initialize the setup for PyCaret\n",
    "setup(data=data, target='species')\n",
    "\n",
    "# Compare models and select the best one\n",
    "best_model = compare_models()\n",
    "\n",
    "# Create the model (e.g., Random Forest)\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Train the model\n",
    "rf_model_trained = finalize_model(rf_model)\n",
    "\n",
    "# Make predictions\n",
    "predictions = predict_model(rf_model_trained)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(rf_model_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf92765-5692-4a9c-b0f1-de8de57e54eb",
   "metadata": {},
   "source": [
    "### Crime Classification using PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7043d8d1-1764-49e5-914b-daa71ff43d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pycaret\n",
    "# location , time_of_day, day_of_week, crime_type\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset (replace with your actual data)\n",
    "data = {\n",
    "    'location': ['Downtown', 'Suburb', 'Downtown', 'Suburb', 'City Center', 'Downtown'],\n",
    "    'time_of_day': ['Morning', 'Evening', 'Afternoon', 'Morning', 'Evening', 'Afternoon'],\n",
    "    'day_of_week': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'],\n",
    "    'crime_type': ['Theft', 'Assault', 'Vandalism', 'Theft', 'Assault', 'Vandalism']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0888076-8ef5-4794-949e-cf6064331337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup() - prepares the data and performs necessary preprocessing like encoding categorical variables, \n",
    "# handling missing values, and scaling features\n",
    "\n",
    "from pycaret.classification import setup\n",
    "\n",
    "#classification\n",
    "setup(data=df, target='crime_type', session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a7364-f142-4022-9c93-61c93f17175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_models - function automatically trains and evaluates multiple models using cross-validation \n",
    "from pycaret.classification import compare_models\n",
    "\n",
    "# Compare different models\n",
    "best_model = compare_models()\n",
    "\n",
    "# based the performances of machine learning models(like Logistic Regression, Random Forest)\n",
    "# It returns the best-performing model based on accuracy or another relevant metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd47d2b-f73c-49d3-91e6-9bc8ee9575ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and train the best model\n",
    "\n",
    "from pycaret.classification import create_model\n",
    "\n",
    "# Create the best model (e.g., Random Forest)\n",
    "model = create_model('rf')  # 'rf' stands for Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bb3ab-aa11-4c8c-bbd8-0fd0f3bcc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import evaluate_model\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cc454-4ba5-4579-817b-b1ecd724b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import predict_model\n",
    "\n",
    "# Example of new data for prediction\n",
    "new_data = pd.DataFrame({\n",
    "    'location': ['Downtown'],\n",
    "    'time_of_day': ['Morning'],\n",
    "    'day_of_week': ['Monday']\n",
    "})\n",
    "\n",
    "# Predict crime type\n",
    "predictions = predict_model(model, data=new_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26aec79-9298-4491-8a68-d6ae1554b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import save_model\n",
    "\n",
    "# Save the trained model\n",
    "save_model(model, 'crime_prediction_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840ca00-c1b6-459f-a67a-083dc289b04e",
   "metadata": {},
   "source": [
    "##### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf4e5214-866d-4e9c-9323-dc7bc24d371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using PyCaret, you can quickly build and evaluate machine learning models to solve problems in public security"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202bc0a6-d7f3-480e-9977-7f596bd4b2fa",
   "metadata": {},
   "source": [
    "####SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ce31c-f343-440b-a2c6-56a243251e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SciPy is an open-source Python library used for scientific and technical computing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
